{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine Tuning DistilBERT for MultiLabel Text Classification - multilingual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn import metrics\n",
    "import transformers\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "import logging\n",
    "logging.basicConfig(level=logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Setting up the device for GPU usage\n",
    "\n",
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hamming_score(y_true, y_pred, normalize=True, sample_weight=None):\n",
    "    acc_list = []\n",
    "    for i in range(y_true.shape[0]):\n",
    "        set_true = set( np.where(y_true[i])[0] )\n",
    "        set_pred = set( np.where(y_pred[i])[0] )\n",
    "        tmp_a = None\n",
    "        if len(set_true) == 0 and len(set_pred) == 0:\n",
    "            tmp_a = 1\n",
    "        else:\n",
    "            tmp_a = len(set_true.intersection(set_pred))/\\\n",
    "                    float( len(set_true.union(set_pred)) )\n",
    "        acc_list.append(tmp_a)\n",
    "    return np.mean(acc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"load dataset\n",
    "\n",
    "name: Bhuvaneshwari/intent_classification\n",
    "from: https://huggingface.co/datasets/Bhuvaneshwari/intent_classification\n",
    "\"\"\"\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"Bhuvaneshwari/intent_classification\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "295c85186dc54a65a1ffdc17fa0ab5ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/405 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae81ae7f655f4eb78ea424df5c824fc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "112e929dccab47918cccefd4a0b5dad5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1012 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 1012\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"load dataset\n",
    "\n",
    "name: mk9165/ko-voicefishing-classification\n",
    "from: https://huggingface.co/datasets/mk9165/ko-voicefishing-classification\n",
    "\"\"\"\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"mk9165/ko-voicefishing-classification\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset['validation'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2ded9d3a0e8419d86aeca5fd434591f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating CSV from Arrow format:   0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2618249"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_filepath = \"dataset/dataset.csv\"\n",
    "dataset['train'].to_csv(train_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>그래요, 어? 일단 차를 알겠고요. 저희들이 kb 금융 기회를 kb 저축은행 인데요...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>네 고객님 감사합니다. 네 아, 근데 제가 지난 보니까는 없으시다고 하던데요? 어느...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>그래요, 어? 일단 차를 알겠고요. 저희들이 kb 금융 기회를 kb 저축은행 인데요...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>네 고객님 감사합니다. 네 아, 근데 제가 지난 보니까는 없으시다고 하던데요? 어느...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>예예예 아이고 통해 보셨어요? 의원님 아 예 좋아했는데요. 이게 좀 이상해요. 내가...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>#@이름#야 직방에 보니까 #@기타# 2억1천짜리도 있네~ 1500도있구? 그르킨 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>거긴 맛있어 ?? 맛있으면 디저트도 ㄱㄱ ㄴㄴ밥먹고옴 구럼 뭐먹고있뉘 음메리카노 라...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>인터넷 뭐 깔러 온대요? 므또새로깐대요? 내일 기사 방문하기로 했다 오후1시 에서 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>자기 웅~~~ 나는 여기 김치찜 남은거랑 컵라면이랑 계란먹어 뭔가 캠핑온거 같아 ㅎ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>저는 오후에 또 출장입니달... 그래도 오늘은 비 안와서 다행이다 ㅠㅠ 덥겠지만,,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1012 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label\n",
       "0     그래요, 어? 일단 차를 알겠고요. 저희들이 kb 금융 기회를 kb 저축은행 인데요...      1\n",
       "1     네 고객님 감사합니다. 네 아, 근데 제가 지난 보니까는 없으시다고 하던데요? 어느...      1\n",
       "2     그래요, 어? 일단 차를 알겠고요. 저희들이 kb 금융 기회를 kb 저축은행 인데요...      1\n",
       "3     네 고객님 감사합니다. 네 아, 근데 제가 지난 보니까는 없으시다고 하던데요? 어느...      1\n",
       "4     예예예 아이고 통해 보셨어요? 의원님 아 예 좋아했는데요. 이게 좀 이상해요. 내가...      1\n",
       "...                                                 ...    ...\n",
       "1007  #@이름#야 직방에 보니까 #@기타# 2억1천짜리도 있네~ 1500도있구? 그르킨 ...      0\n",
       "1008  거긴 맛있어 ?? 맛있으면 디저트도 ㄱㄱ ㄴㄴ밥먹고옴 구럼 뭐먹고있뉘 음메리카노 라...      0\n",
       "1009  인터넷 뭐 깔러 온대요? 므또새로깐대요? 내일 기사 방문하기로 했다 오후1시 에서 ...      0\n",
       "1010  자기 웅~~~ 나는 여기 김치찜 남은거랑 컵라면이랑 계란먹어 뭔가 캠핑온거 같아 ㅎ...      0\n",
       "1011  저는 오후에 또 출장입니달... 그래도 오늘은 비 안와서 다행이다 ㅠㅠ 덥겠지만,,...      0\n",
       "\n",
       "[1012 rows x 2 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(train_filepath)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '0', 1: '1'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# labels = set(df[\"label\"].values.tolist())\n",
    "# labels_dict = dict()\n",
    "# for i, label in enumerate(labels):\n",
    "#     labels_dict[label] = str(i)\n",
    "# labels_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['label'] = df['label'].apply(lambda x: labels_dict[x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label_0</th>\n",
       "      <th>label_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1012 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label_0  label_1\n",
       "0           0        1\n",
       "1           0        1\n",
       "2           0        1\n",
       "3           0        1\n",
       "4           0        1\n",
       "...       ...      ...\n",
       "1007        1        0\n",
       "1008        1        0\n",
       "1009        1        0\n",
       "1010        1        0\n",
       "1011        1        0\n",
       "\n",
       "[1012 rows x 2 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# label_df = pd.get_dummies(df['labels'], dtype=int)\n",
    "onehot_df = pd.get_dummies(df['label'], prefix='label', dtype=int)\n",
    "sorted_colums = sorted(onehot_df.columns, key=lambda x: int(x.split('_')[1]))\n",
    "onehot_df = onehot_df[sorted_colums]\n",
    "onehot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>그래요, 어? 일단 차를 알겠고요. 저희들이 kb 금융 기회를 kb 저축은행 인데요...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>네 고객님 감사합니다. 네 아, 근데 제가 지난 보니까는 없으시다고 하던데요? 어느...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>그래요, 어? 일단 차를 알겠고요. 저희들이 kb 금융 기회를 kb 저축은행 인데요...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>네 고객님 감사합니다. 네 아, 근데 제가 지난 보니까는 없으시다고 하던데요? 어느...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>예예예 아이고 통해 보셨어요? 의원님 아 예 좋아했는데요. 이게 좀 이상해요. 내가...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>#@이름#야 직방에 보니까 #@기타# 2억1천짜리도 있네~ 1500도있구? 그르킨 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>거긴 맛있어 ?? 맛있으면 디저트도 ㄱㄱ ㄴㄴ밥먹고옴 구럼 뭐먹고있뉘 음메리카노 라...</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>인터넷 뭐 깔러 온대요? 므또새로깐대요? 내일 기사 방문하기로 했다 오후1시 에서 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>자기 웅~~~ 나는 여기 김치찜 남은거랑 컵라면이랑 계란먹어 뭔가 캠핑온거 같아 ㅎ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>저는 오후에 또 출장입니달... 그래도 오늘은 비 안와서 다행이다 ㅠㅠ 덥겠지만,,...</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1012 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label  labels\n",
       "0     그래요, 어? 일단 차를 알겠고요. 저희들이 kb 금융 기회를 kb 저축은행 인데요...      1  [0, 1]\n",
       "1     네 고객님 감사합니다. 네 아, 근데 제가 지난 보니까는 없으시다고 하던데요? 어느...      1  [0, 1]\n",
       "2     그래요, 어? 일단 차를 알겠고요. 저희들이 kb 금융 기회를 kb 저축은행 인데요...      1  [0, 1]\n",
       "3     네 고객님 감사합니다. 네 아, 근데 제가 지난 보니까는 없으시다고 하던데요? 어느...      1  [0, 1]\n",
       "4     예예예 아이고 통해 보셨어요? 의원님 아 예 좋아했는데요. 이게 좀 이상해요. 내가...      1  [0, 1]\n",
       "...                                                 ...    ...     ...\n",
       "1007  #@이름#야 직방에 보니까 #@기타# 2억1천짜리도 있네~ 1500도있구? 그르킨 ...      0  [1, 0]\n",
       "1008  거긴 맛있어 ?? 맛있으면 디저트도 ㄱㄱ ㄴㄴ밥먹고옴 구럼 뭐먹고있뉘 음메리카노 라...      0  [1, 0]\n",
       "1009  인터넷 뭐 깔러 온대요? 므또새로깐대요? 내일 기사 방문하기로 했다 오후1시 에서 ...      0  [1, 0]\n",
       "1010  자기 웅~~~ 나는 여기 김치찜 남은거랑 컵라면이랑 계란먹어 뭔가 캠핑온거 같아 ㅎ...      0  [1, 0]\n",
       "1011  저는 오후에 또 출장입니달... 그래도 오늘은 비 안와서 다행이다 ㅠㅠ 덥겠지만,,...      0  [1, 0]\n",
       "\n",
       "[1012 rows x 3 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['labels'] = onehot_df.values.tolist()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>그래요, 어? 일단 차를 알겠고요. 저희들이 kb 금융 기회를 kb 저축은행 인데요...</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>네 고객님 감사합니다. 네 아, 근데 제가 지난 보니까는 없으시다고 하던데요? 어느...</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>그래요, 어? 일단 차를 알겠고요. 저희들이 kb 금융 기회를 kb 저축은행 인데요...</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>네 고객님 감사합니다. 네 아, 근데 제가 지난 보니까는 없으시다고 하던데요? 어느...</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>예예예 아이고 통해 보셨어요? 의원님 아 예 좋아했는데요. 이게 좀 이상해요. 내가...</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>#@이름#야 직방에 보니까 #@기타# 2억1천짜리도 있네~ 1500도있구? 그르킨 ...</td>\n",
       "      <td>[1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>거긴 맛있어 ?? 맛있으면 디저트도 ㄱㄱ ㄴㄴ밥먹고옴 구럼 뭐먹고있뉘 음메리카노 라...</td>\n",
       "      <td>[1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>인터넷 뭐 깔러 온대요? 므또새로깐대요? 내일 기사 방문하기로 했다 오후1시 에서 ...</td>\n",
       "      <td>[1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>자기 웅~~~ 나는 여기 김치찜 남은거랑 컵라면이랑 계란먹어 뭔가 캠핑온거 같아 ㅎ...</td>\n",
       "      <td>[1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>저는 오후에 또 출장입니달... 그래도 오늘은 비 안와서 다행이다 ㅠㅠ 덥겠지만,,...</td>\n",
       "      <td>[1, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1012 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  labels\n",
       "0     그래요, 어? 일단 차를 알겠고요. 저희들이 kb 금융 기회를 kb 저축은행 인데요...  [0, 1]\n",
       "1     네 고객님 감사합니다. 네 아, 근데 제가 지난 보니까는 없으시다고 하던데요? 어느...  [0, 1]\n",
       "2     그래요, 어? 일단 차를 알겠고요. 저희들이 kb 금융 기회를 kb 저축은행 인데요...  [0, 1]\n",
       "3     네 고객님 감사합니다. 네 아, 근데 제가 지난 보니까는 없으시다고 하던데요? 어느...  [0, 1]\n",
       "4     예예예 아이고 통해 보셨어요? 의원님 아 예 좋아했는데요. 이게 좀 이상해요. 내가...  [0, 1]\n",
       "...                                                 ...     ...\n",
       "1007  #@이름#야 직방에 보니까 #@기타# 2억1천짜리도 있네~ 1500도있구? 그르킨 ...  [1, 0]\n",
       "1008  거긴 맛있어 ?? 맛있으면 디저트도 ㄱㄱ ㄴㄴ밥먹고옴 구럼 뭐먹고있뉘 음메리카노 라...  [1, 0]\n",
       "1009  인터넷 뭐 깔러 온대요? 므또새로깐대요? 내일 기사 방문하기로 했다 오후1시 에서 ...  [1, 0]\n",
       "1010  자기 웅~~~ 나는 여기 김치찜 남은거랑 컵라면이랑 계란먹어 뭔가 캠핑온거 같아 ㅎ...  [1, 0]\n",
       "1011  저는 오후에 또 출장입니달... 그래도 오늘은 비 안와서 다행이다 ㅠㅠ 덥겠지만,,...  [1, 0]\n",
       "\n",
       "[1012 rows x 2 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(['label'], axis=1, inplace=True)\n",
    "new_df = df\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv('train.csv')\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sections of config\n",
    "\n",
    "# Defining some key variables that will be used later on in the training\n",
    "MAX_LEN = 128\n",
    "TRAIN_BATCH_SIZE = 4\n",
    "VALID_BATCH_SIZE = 4\n",
    "EPOCHS = 1\n",
    "LEARNING_RATE = 1e-05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert/distilbert-base-multilingual-cased', truncation=True, do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLabelDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = dataframe\n",
    "        self.text = dataframe.text\n",
    "        self.targets = self.data.labels\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = str(self.text[index])\n",
    "        text = \" \".join(text.split())\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            pad_to_max_length=True,\n",
    "            return_token_type_ids=True\n",
    "        )\n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "        token_type_ids = inputs[\"token_type_ids\"]\n",
    "\n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
    "            'targets': torch.tensor(self.targets[index], dtype=torch.float)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL Dataset: (1012, 2)\n",
      "TRAIN Dataset: (810, 2)\n",
      "TEST Dataset: (202, 2)\n"
     ]
    }
   ],
   "source": [
    "# Creating the dataset and dataloader for the neural network\n",
    "train_size = 0.8\n",
    "train_data=new_df.sample(frac=train_size,random_state=200)\n",
    "test_data=new_df.drop(train_data.index).reset_index(drop=True)\n",
    "train_data = train_data.reset_index(drop=True)\n",
    "\n",
    "print(\"FULL Dataset: {}\".format(new_df.shape))\n",
    "print(\"TRAIN Dataset: {}\".format(train_data.shape))\n",
    "print(\"TEST Dataset: {}\".format(test_data.shape))\n",
    "\n",
    "training_set = MultiLabelDataset(train_data, tokenizer, MAX_LEN)\n",
    "testing_set = MultiLabelDataset(test_data, tokenizer, MAX_LEN)\n",
    "# training_set = MultiLabelDataset(train_data, tokenizer)\n",
    "# testing_set = MultiLabelDataset(test_data, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  labels\n",
      "0  그래요, 어? 일단 차를 알겠고요. 저희들이 kb 금융 기회를 kb 저축은행 인데요...  [0, 1]\n",
      "1  그래요, 어? 일단 차를 알겠고요. 저희들이 kb 금융 기회를 kb 저축은행 인데요...  [0, 1]\n",
      "2  여보세요 네. 네 아 네 어저께 통화했던 최고 아닙니다. 어떻게 가족의 결과 안내?...  [0, 1]\n",
      "3  여보세요? 안녕하세요, 고객님. 김종현 대리 입니다. 아 예 대리님, 예 고객님, ...  [0, 1]\n",
      "4  에 가정 내 여보세요? 아 내고 있는 선호주였던 하나 기타 김민기 드립니다. 아 네...  [0, 1]\n",
      "5  네, 혹시 진행이 어떻게 들어가고 있으신가요? 아, 아직 본사 신이 전화를 못 받았...  [0, 1]\n",
      "6  여보세요 님? 네, 그 저희 쪽 국민은행 쪽에서 의 요청이 들어와서 연락드렸는데요....  [0, 1]\n",
      "7  여보세요? 네네 아까 전에 통화 도움 드렸던 담당자 이 세리에 요 네네네 저희 고객...  [0, 1]\n",
      "8  네 여보세요 네 여보세요. 네 아 예 선생님 일단 확인 됐구요. 그 발급 비용 같은...  [0, 1]\n",
      "9  안녕하세요. 예 여보세요 여보세요 입니다. 고객님 어 지금 전산 내려가지고 연락을 ...  [0, 1]\n",
      "                                                  text  labels\n",
      "192  플립은 전용보험써야한대 그래서 6300원.. 엥 그런것도 있음? 응 그렇다네..? ...  [1, 0]\n",
      "193  ㅋㅋㅋㅋ카페왓는ㄷ0 #@이름#언니랑 #@이름#언니만남 바로뒤에있었어.... ㅌㅋㅋㅋ...  [1, 0]\n",
      "194  오늘 뭐 묵고싶어?ㅋ 글쎄..겹살에 쏘주를해야하나..회식을해봤어야알지 ㅋㅋ 여봉이 ...  [1, 0]\n",
      "195  다 배우면 지들 오빠 가게에서 네일샵하는거임? 아니아니 이제는 파트타임 직원으로 하...  [1, 0]\n",
      "196  어디묘? 지내동 삼거리~ 오 128? 마치자마자 곧장 집으로 출발함ㅋㅋㅋ 엉엉 난 ...  [1, 0]\n",
      "197  버킷햇..햇빛은 가려주는데 그 모자 닿이는 이마 부분에 땀이 땀이..ㅎㅎ !! 여름...  [1, 0]\n",
      "198  나 어제저녁굶어서 이제다이어트할수있을거같아 ㅎㅎ진짜 진심이야 어제?! 나는 쭈욱.....  [1, 0]\n",
      "199  아자야되는데 밤낮버뀐거 우쨔냨ㅋㄱㄱㄱㅋ 나도 새벽에 깨서 여태 놈 진짜ㅔ최악으로 바...  [1, 0]\n",
      "200  거긴 맛있어 ?? 맛있으면 디저트도 ㄱㄱ ㄴㄴ밥먹고옴 구럼 뭐먹고있뉘 음메리카노 라...  [1, 0]\n",
      "201  인터넷 뭐 깔러 온대요? 므또새로깐대요? 내일 기사 방문하기로 했다 오후1시 에서 ...  [1, 0]\n"
     ]
    }
   ],
   "source": [
    "print(test_data[:10])\n",
    "print(test_data[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "그래요, 어? 일단 차를 알겠고요. 저희들이 kb 금융 기회를 kb 저축은행 인데요. 지금 5월 달에 저희들이 대환 대출 플러스 생활의 자금 쪽으로 나온 대출상품 있어요. 어 네, 그리고 이은 2월 이 7.8% 대로 진행하는 부분이고 상환기간이 운행 가지고요. 중도상환 가능하고 수수료 발생이 없이 원리금 균등 분할상환 혹은 만기일시상환 쪽으로 이자만 갚을 해도 되는 부분이에요. 네, 그리고 최근 맥심 대환대출 플러스 생활자금 쪽으로 오 천만원까지 인데 오천만원 검토 다 받으실 거예요? 일단 잘 알고 있구요, 지금? 맞으시죠? 예 고객님, 혹시 지금? 그 사용하고 있는 휴대폰은 본인 이름으로 돼 있는 거 맞으세요? 어? 이 통신사는 skt lg 예요. 예 삼성 스마트폰 맞으세요? 혹시 카톡을 사용하고 계세요? 그러면은요 카톡 추가를 해서 저희들 회사 상하고 제 이름 넣어드릴게요. 왜요? 예, 왜요? 예 고객님, 저한테 전화를 주셔서 통화 중에? 제가 전화를 못 받으면 카톡으로 이 연락을 할 수도 있을 있어서 그런 거 아니에요? 아니에요? 네 전화를 주시면?\n",
      "[0, 1]\n"
     ]
    }
   ],
   "source": [
    "print(test_data[:10]['text'][0])\n",
    "print(test_data[:10]['labels'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "플립은 전용보험써야한대 그래서 6300원.. 엥 그런것도 있음? 응 그렇다네..? 개양아치야.. 방금 가입할라고 들어가니까 극게그거지.. 6300원밖에ㅜ없더라 ㅠ\n",
      "[1, 0]\n"
     ]
    }
   ],
   "source": [
    "print(test_data[-10:].reset_index(drop=True)['text'][0])\n",
    "print(test_data[-10:].reset_index(drop=True)['labels'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "training_loader = DataLoader(training_set, **train_params)\n",
    "testing_loader = DataLoader(testing_set, **test_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Neural Network for Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the customized model, by adding a drop out and a dense layer on top of distil bert to get the final output for the model.\n",
    "class DistilBERTClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DistilBERTClass, self).__init__()\n",
    "        # self.l1 = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "        self.l1 = DistilBertModel.from_pretrained(\"distilbert/distilbert-base-multilingual-cased\")\n",
    "        self.pre_classifier = torch.nn.Linear(768, 768)\n",
    "        self.dropout = torch.nn.Dropout(0.1)\n",
    "        # self.classifier = torch.nn.Linear(768, 12)\n",
    "        self.classifier = torch.nn.Linear(768, 2)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        output_1 = self.l1(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        hidden_state = output_1[0]\n",
    "        pooler = hidden_state[:, 0]\n",
    "        pooler = self.pre_classifier(pooler)\n",
    "        pooler = torch.nn.Tanh()(pooler)\n",
    "        pooler = self.dropout(pooler)\n",
    "        output = self.classifier(pooler)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBERTClass(\n",
       "  (l1): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DistilBERTClass()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(outputs, targets):\n",
    "    return torch.nn.BCEWithLogitsLoss()(outputs, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    for _,data in tqdm(enumerate(training_loader, 0)):\n",
    "        ids = data['ids'].to(device, dtype = torch.long)\n",
    "        mask = data['mask'].to(device, dtype = torch.long)\n",
    "        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "        targets = data['targets'].to(device, dtype = torch.float)\n",
    "\n",
    "        outputs = model(ids, mask, token_type_ids)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        if _%5000==0:\n",
    "            print(f'Epoch: {epoch}, Loss:  {loss.item()}')\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00, 18.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss:  0.6766570806503296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "203it [00:05, 38.81it/s]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(testing_loader):\n",
    "    model.eval()\n",
    "    fin_targets=[]\n",
    "    fin_outputs=[]\n",
    "    with torch.no_grad():\n",
    "        for _, data in tqdm(enumerate(testing_loader, 0)):\n",
    "            ids = data['ids'].to(device, dtype = torch.long)\n",
    "            mask = data['mask'].to(device, dtype = torch.long)\n",
    "            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "            targets = data['targets'].to(device, dtype = torch.float)\n",
    "            outputs = model(ids, mask, token_type_ids)\n",
    "            fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
    "            fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
    "    return fin_outputs, fin_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "51it [00:01, 48.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs:\n",
      "[[0.015593708492815495, 0.9839683771133423], [0.012718467973172665, 0.9867292642593384], [0.987812340259552, 0.01133679784834385], [0.015973716974258423, 0.9837032556533813], [0.9867156147956848, 0.01211388036608696], [0.9875983595848083, 0.011204879730939865], [0.9871152639389038, 0.013136222027242184], [0.9881227612495422, 0.011964518576860428], [0.01599281094968319, 0.9834138751029968], [0.013309494592249393, 0.986107587814331]]\n",
      "targets:\n",
      "[[0.0, 1.0], [0.0, 1.0], [1.0, 0.0], [0.0, 1.0], [1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [0.0, 1.0], [0.0, 1.0]]\n",
      "final outputs:\n",
      "[[False  True]\n",
      " [False  True]\n",
      " [ True False]\n",
      " [False  True]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [False  True]\n",
      " [False  True]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "output, targets = validation(testing_loader)\n",
    "print(f\"outputs:\\n{output[:10]}\")\n",
    "print(f\"targets:\\n{targets[:10]}\")\n",
    "\n",
    "final_outputs = np.array(output) >=0.5\n",
    "print(f\"final outputs:\\n{final_outputs[:10]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 0, 1, 0, 0, 0, 0, 1, 1]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "list(map(lambda x: np.where(x == True)[0].item(), final_outputs[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming Score = 0.995049504950495\n",
      "Hamming Loss = 0.0049504950495049506\n"
     ]
    }
   ],
   "source": [
    "val_hamming_loss = metrics.hamming_loss(targets, final_outputs)\n",
    "val_hamming_score = hamming_score(np.array(targets), np.array(final_outputs))\n",
    "\n",
    "print(f\"Hamming Score = {val_hamming_score}\")\n",
    "print(f\"Hamming Loss = {val_hamming_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the files for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "today = datetime.now().strftime(\"%Y%m%d\")\n",
    "output_model_file = './output/pytorch_distilbert_{}.bin'.format(today)\n",
    "output_vocab_file = './output/vocab_distilbert_{}.bin'.format(today)\n",
    "\n",
    "torch.save(model, output_model_file)\n",
    "tokenizer.save_vocabulary(output_vocab_file)\n",
    "\n",
    "print('Saved')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
